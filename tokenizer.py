

with open('data.txt', 'r') as file:
    

def tokenizer(text : str):
    tokens = text.split()